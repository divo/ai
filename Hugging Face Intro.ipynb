{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cecf2686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.28.0 \n",
    "!pip install -Uq datasets torch soundfile librosa beautifulsoup4 lxml accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a8aec",
   "metadata": {},
   "source": [
    "## Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029b81f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5268cbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998362064361572}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you this library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19bfa878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e0b79",
   "metadata": {},
   "source": [
    "## Audio Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef6d983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset minds14 (/Users/stevendiviney/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/65c7e0f3be79e18a6ffaf879a083daf706312d421ac90d25718459cbf3c42696)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a247de",
   "metadata": {},
   "source": [
    "You need to make sure the sampling rate of the dataset matches the sampling rate facebook/wav2vec2-base-960h was trained on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6284c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f73248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I'M HOPING YOU CAN HELP ME I CAN'T ACCESS MY ACCOUNT IT JUST SAYS THAT THE ABT IS BEING SERVICED\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "idx = 200\n",
    "result = speech_recognizer(dataset[idx][\"audio\"])\n",
    "print(result['text'])\n",
    "#!afplay {dataset[idx]['audio']['path']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d81ad",
   "metadata": {},
   "source": [
    "## Document summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf56888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b6cbe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men, and at one time, she was married to eight men.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfaea7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "link = \"https://thehftguy.com/2023/05/16/why-are-there-no-antitrust-claims-vs-github-copilot-when-there-is-a-precedent/\"\n",
    "\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "res = soup.findAll(\"article\")\n",
    "# This is not a very good approach\n",
    "##summarizer(article_text[:500])\n",
    "#summary = []\n",
    "#for par in res[0].find_all('p'):\n",
    "#   summary += summarizer(par.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5d1db",
   "metadata": {},
   "source": [
    "### Summarization tutorial\n",
    "https://huggingface.co/docs/transformers/tasks/summarization\n",
    "\n",
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4687c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (4.28.0)\n",
      "Requirement already satisfied: datasets in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: evaluate in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: rouge_score in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: pandas in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: multiprocess in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: click in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a9eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset billsum (/Users/stevendiviney/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")\n",
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b28753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Existing law makes it unlawful for any person to operate a vessel or water-related device while under the influence of an alcoholic beverage or any drug, or both. Existing law directs the administration of a chemical test that is used to analyze an individual’s breath, blood, or urine for evidence of drug or alcohol use when the individual is arrested for these actions. Existing law requires the arrested individual to be informed that a refusal to submit to, or failure to complete, the required chemical testing may be used against the person in court and that the court, upon convicting the arrested individual, may impose increased penalties for his or her refusal or failure.\\nThis bill would instead require the arrested individual to be advised that a criminal complaint may be filed against him or her for operating a vessel or water-related device while under the influence of an alcoholic beverage or any drug, or both; that he or she has a right to refuse chemical testing; and that the officer has the authority to seek a search warrant compelling him or her to submit a blood sample. By imposing new duties on local peace officers, this bill would impose a state-mandated local program.\\nThe California Constitution requires the state to reimburse local agencies and school districts for certain costs mandated by the state. Statutory provisions establish procedures for making that reimbursement.\\nThis bill would provide that, if the Commission on State Mandates determines that the bill contains costs mandated by the state, reimbursement for those costs shall be made pursuant to these statutory provisions.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum[\"train\"][0][\"summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d2c6d",
   "metadata": {},
   "source": [
    "#### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dc9ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93bd6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "    \n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e54fdec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5cf66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c35668",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "Using the ROUGE metric. ROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics and a software package used for evaluating automatic summarization and machine translation software in natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2ec0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00c8fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdc38a",
   "metadata": {},
   "source": [
    "#### Train\n",
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f9e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevendiviney/.pyenv/versions/3.9.4/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 81/248 21:29 < 45:26, 0.06 it/s, Epoch 1.29/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.813490</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"billsum_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
